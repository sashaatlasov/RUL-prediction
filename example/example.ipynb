{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58968975-d835-43b5-948a-32cccc565d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: rulprediction 1.0\n",
      "Uninstalling rulprediction-1.0:\n",
      "  Successfully uninstalled rulprediction-1.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall rulprediction --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39a9d7fb-9b67-474f-810c-1d1e6ca8084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/sashaatlasov/RUL-Prediction.git\n",
      "  Cloning https://github.com/sashaatlasov/RUL-Prediction.git to /private/var/folders/cr/12mnwryn4bj3dhrct6_xvw340000gn/T/pip-req-build-ei5r31ms\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/sashaatlasov/RUL-Prediction.git /private/var/folders/cr/12mnwryn4bj3dhrct6_xvw340000gn/T/pip-req-build-ei5r31ms\n",
      "  Resolved https://github.com/sashaatlasov/RUL-Prediction.git to commit 92b50da7aa6e741abd034345284a807ace820d6e\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: rulprediction\n",
      "  Building wheel for rulprediction (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rulprediction: filename=rulprediction-1.0-py3-none-any.whl size=10123 sha256=ec4c6b837599eefb1d29279beeedf947c847c8fb48a764600eb18cbf9f1a9f1d\n",
      "  Stored in directory: /private/var/folders/cr/12mnwryn4bj3dhrct6_xvw340000gn/T/pip-ephem-wheel-cache-i149e0ro/wheels/d9/26/2f/4a379e714991d395b358c8aebe5b708c26e61c28df8e5e8036\n",
      "Successfully built rulprediction\n",
      "Installing collected packages: rulprediction\n",
      "Successfully installed rulprediction-1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/sashaatlasov/RUL-Prediction.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0410c6d9-95b8-4cde-9c35-12a254434f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f6ea706-19cf-450b-b1ae-6a01c52a5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMAPSS(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        sensors = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        return target, sensors.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0540cbf-6494-4b9b-8aa7-1f5878c3b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(k):\n",
    "    X_train = sio.loadmat(f'data/F00{k}/trainX.mat')['trainX']\n",
    "    X_test = sio.loadmat(f'data/F00{k}/testX.mat')['testX']\n",
    "\n",
    "    y_train = sio.loadmat(f'data/F00{k}/trainY.mat')['trainY'].T\n",
    "    y_test = sio.loadmat(f'data/F00{k}/testY.mat')['testY'].T\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.2, random_state=1)\n",
    "    \n",
    "    train_data = CMAPSS(X_train, y_train) \n",
    "    val_data = CMAPSS(X_val, y_val) \n",
    "    test_data = CMAPSS(X_test, y_test) \n",
    "                        \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=256, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=256)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=256)\n",
    "                        \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3dd5c238-e8f5-4560-89c6-a010f862fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rulpred.RULprediction import RULpredictor\n",
    "from rulpred.training import *\n",
    "\n",
    "from hparams import config\n",
    "\n",
    "def main(k, device='cpu', num_epochs=100):\n",
    "    if k % 2 == 0:\n",
    "        win_size = 60\n",
    "    else:\n",
    "        win_size = 40\n",
    "        \n",
    "    model = RULpredictor(win_size)\n",
    "    model.to(device)\n",
    "\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate_start\"])\n",
    "    train_dataloader, val_dataloader, test_dataloader = get_data(k)\n",
    "\n",
    "    for i in range(1, 1 + 1):\n",
    "        loss = train_epoch(model, train_dataloader, optim, device=device)\n",
    "        if i % 5 == 0:\n",
    "            val_loss = validate(model, val_dataloader, device)\n",
    "    test_loss = validate(model, test_dataloader, device)\n",
    "    torch.save(model, f'Model_F00{k}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8163ed6a-74c7-4503-a085-b2ade4dd0703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.0125: 100%|██████████| 53/53 [00:30<00:00,  1.75it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.8/site-packages/rulpred/training.py:34: UserWarning: Using a target size (torch.Size([100, 1])) that is different to the input size (torch.Size([100, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(mean * 125, t * 125, reduction='none')\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.98s/it]\n"
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4df673b2-65a0-47fa-a027-7232b6b46024",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/sasaatlasov/Desktop/DAST-main/Model_trained/F001_DAST_prediciton_model_11.40'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dast \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/sasaatlasov/Desktop/DAST-main/Model_trained/F001_DAST_prediciton_model_11.40\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/sasaatlasov/Desktop/DAST-main/Model_trained/F001_DAST_prediciton_model_11.40'"
     ]
    }
   ],
   "source": [
    "from rulpred.tr\n",
    "dast = torch.load('/Users/sasaatlasov/Desktop/DAST-main/Model_trained/F001_DAST_prediciton_model_11.40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dadd6ba9-32d0-4093-be3a-b940ab1d99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('Model_F001.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdfe89a3-72d0-4d62-9405-8594f2e4aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rulpred.evaluation.plot_prediction import plot_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6ffab-4964-497f-adec-c469049bbe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traj(24, model, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07290e90-3703-4874-98dc-835e25f61a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3633d5a-7338-4288-b027-4166f7f3ed92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
