{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58968975-d835-43b5-948a-32cccc565d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: rulprediction 1.0\n",
      "Uninstalling rulprediction-1.0:\n",
      "  Successfully uninstalled rulprediction-1.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall rulprediction --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a9d7fb-9b67-474f-810c-1d1e6ca8084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/sashaatlasov/RUL-Prediction.git\n",
      "  Cloning https://github.com/sashaatlasov/RUL-Prediction.git to /private/var/folders/cr/12mnwryn4bj3dhrct6_xvw340000gn/T/pip-req-build-7nrd032b\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/sashaatlasov/RUL-Prediction.git /private/var/folders/cr/12mnwryn4bj3dhrct6_xvw340000gn/T/pip-req-build-7nrd032b\n",
      "  Resolved https://github.com/sashaatlasov/RUL-Prediction.git to commit 54b7831afdba2a2761b6e84cca47c961ddc80caf\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: rulprediction\n",
      "  Building wheel for rulprediction (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rulprediction: filename=rulprediction-1.0-py3-none-any.whl size=8882 sha256=daeca179a764796005332dd355714a42e432d68872c2ef1ba0f65eb5fd7419d7\n",
      "  Stored in directory: /private/var/folders/cr/12mnwryn4bj3dhrct6_xvw340000gn/T/pip-ephem-wheel-cache-i4xycg_m/wheels/d9/26/2f/4a379e714991d395b358c8aebe5b708c26e61c28df8e5e8036\n",
      "Successfully built rulprediction\n",
      "Installing collected packages: rulprediction\n",
      "Successfully installed rulprediction-1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/sashaatlasov/RUL-Prediction.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0410c6d9-95b8-4cde-9c35-12a254434f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f6ea706-19cf-450b-b1ae-6a01c52a5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMAPSS(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        sensors = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        return target, sensors.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0540cbf-6494-4b9b-8aa7-1f5878c3b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(k):\n",
    "    X_train = sio.loadmat(f'data/F00{k}/trainX.mat')['trainX']\n",
    "    X_test = sio.loadmat(f'data/F00{k}/testX.mat')['testX']\n",
    "\n",
    "    y_train = sio.loadmat(f'data/F00{k}/trainY.mat')['trainY'].T\n",
    "    y_test = sio.loadmat(f'data/F00{k}/testY.mat')['testY'].T\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.2, random_state=1)\n",
    "    \n",
    "    train_data = CMAPSS(X_train, y_train) \n",
    "    val_data = CMAPSS(X_val, y_val) \n",
    "    test_data = CMAPSS(X_test, y_test) \n",
    "                        \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=256, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=256)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=256)\n",
    "                        \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dd5c238-e8f5-4560-89c6-a010f862fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rulpred.RULprediction import RULpredictor\n",
    "from rulpred.training import *\n",
    "\n",
    "from hparams import config\n",
    "\n",
    "def main(k, device='cpu', num_epochs=100):\n",
    "    if k % 2 == 0:\n",
    "        win_size = 60\n",
    "    else:\n",
    "        win_size = 40\n",
    "        \n",
    "    model = RULpredictor(win_size)\n",
    "    model.to(device)\n",
    "\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate_start\"])\n",
    "    train_dataloader, val_dataloader, test_dataloader = get_data(k)\n",
    "\n",
    "    for i in range(1, 1 + 1):\n",
    "        loss = train_epoch(model, train_dataloader, optim, device=device)\n",
    "        if i % 5 == 0:\n",
    "            val_loss = validate(model, val_dataloader, device)\n",
    "    test_loss = validate(model, test_dataloader, device)\n",
    "    torch.save(model, f'Model_F00{k}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8163ed6a-74c7-4503-a085-b2ade4dd0703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.0125: 100%|██████████| 53/53 [00:30<00:00,  1.75it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.8/site-packages/rulpred/training.py:34: UserWarning: Using a target size (torch.Size([100, 1])) that is different to the input size (torch.Size([100, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(mean * 125, t * 125, reduction='none')\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.98s/it]\n"
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4df673b2-65a0-47fa-a027-7232b6b46024",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'DAST_Network'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dast \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/sasaatlasov/Desktop/DAST-main/Model_trained/F001_DAST_prediciton_model_11.40\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1014\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1021\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1421\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1422\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1425\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1427\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:1415\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[0;32m-> 1415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'DAST_Network'"
     ]
    }
   ],
   "source": [
    "dast = torch.load('/Users/sasaatlasov/Desktop/DAST-main/Model_trained/F001_DAST_prediciton_model_11.40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dadd6ba9-32d0-4093-be3a-b940ab1d99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('Model_F001.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdfe89a3-72d0-4d62-9405-8594f2e4aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rulpred.evaluation.plot_prediction import plot_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6ffab-4964-497f-adec-c469049bbe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traj(24, model, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07290e90-3703-4874-98dc-835e25f61a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3633d5a-7338-4288-b027-4166f7f3ed92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
